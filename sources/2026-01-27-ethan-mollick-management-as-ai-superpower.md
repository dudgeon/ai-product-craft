---
title: "Management as AI Superpower | Ethan Mollick"
created: 2026-02-16
updated: 2026-02-16
template: templates/source.md
template_version: 3
tags: [source, ai-pm]
status: read
source_type: newsletter
source_url: "https://www.oneusefulthing.org/p/management-as-ai-superpower"
archive_url: ""
author: "Ethan Mollick"
host: ""
published: 2026-01-27
discovered: 2026-02-14
summary: "Ethan Mollick (Wharton professor, One Useful Thing) argues that management skills are the key competitive advantage in working with AI. Introduces a three-variable delegation framework: Human Baseline Time × Probability of Success × AI Process Time — delegation is worthwhile when the human task is long, AI success probability is high, and evaluation time is low. References OpenAI's GDPval study where GPT-5.2 tied or beat human experts 72% of the time on 7-hour professional tasks. MBA students in a 4-day UPenn startup experiment accomplished an order of magnitude more than pre-AI semester-long classes by applying management skills (scoping, delegation, evaluation) rather than AI-specific prompting. Every field has invented delegation documentation (PRDs, shot lists, Five Paragraph Orders) — all work remarkably well as AI prompts. Core insight: what's scarce is not talent (AI provides that) but knowing what to ask for."
domain: professional-development
project: ai-pm
---

# Management as AI Superpower | Ethan Mollick

**By**: Ethan Mollick
**Source**: [One Useful Thing](https://www.oneusefulthing.org/p/management-as-ai-superpower)
**Type**: newsletter

## Summary

Ethan Mollick makes the case that management — not prompting, not AI literacy — is the core skill for the agentic era. He introduces a delegation decision framework based on three variables (human baseline time, probability of AI success, and AI process time for evaluation) and backs it with OpenAI's GDPval benchmark data showing AI matching or beating experts on professional tasks. His MBA students at UPenn accomplished dramatically more in 4 days with AI than pre-AI students did in a full semester, not because they were AI experts but because they already knew how to scope problems, define deliverables, and evaluate outputs.

## Key Ideas Extracted

- **Three-variable delegation framework**: Human Baseline Time × Probability of Success × AI Process Time — the math determines when delegation is worthwhile; high human time + high AI success rate + low evaluation time = delegate
- **Management skills as AI competitive advantage**: Scoping problems, defining deliverables, recognizing quality, giving feedback — these "soft" skills are the hard ones in the agentic era
- **GDPval benchmark shift**: GPT-5.2 tied or beat human experts 72% of the time on complex 7-hour professional tasks; expert evaluation took ~1 hour — the equation now favors delegation for most complex work
- **Order-of-magnitude acceleration with AI**: MBA students in a 4-day startup experiment accomplished more than pre-AI students did in a full semester — prototypes with working core features, diverse ideas, insightful market analyses
- **Delegation documentation as AI prompts**: Every field already has formats for delegation (PRDs, shot lists, Five Paragraph Orders, engagement scopes) — these all work as AI prompts because they solve the same problem: getting what's in one person's head into another's actions
- **Three levers for improving AI delegation**: Give better instructions (clear goals), get better at evaluation/feedback (fewer iterations), make evaluation cheaper (faster quality assessment) — all improved by subject matter expertise
- **Scarcity shift from talent to direction**: AI makes talent abundant and cheap; what's scarce is knowing what to ask for — the people who thrive will know what good looks like and can explain it clearly
- **Jagged Frontier applies to delegation decisions**: You don't reliably know what AI will be good or bad at on complex tasks, but it's fast and cheap — generate multiple versions and throw most away
- **Lowered cost of pivoting**: AI dramatically reduces the cost of pivoting a startup, making it viable to explore multiple directions or even multiple startups at once

## Notes

- Published Jan 27, 2026 on One Useful Thing (Substack). Free article (no paywall).
- Ethan Mollick: Professor at Wharton, author of "Co-Intelligence," widely cited AI-and-work researcher
- References his own Jagged Frontier paper and GDPval discussion
- Claude Code specifically mentioned — used it to generate a full 1980s adventure game with one prompt, deployed in three prompts total
- Google Antigravity also mentioned as tool students used
- Software development highlighted as first profession to feel the management shift (clearly verifiable outputs, mature tooling)
- Strong connection to CHJ/Scaling Agents concepts — the delegation documentation inventory (PRDs, shot lists, Five Paragraph Orders) maps to the Mechanism Layer thesis
- Cross-references: Relates to the Scaling People → Scaling Agents inbox item's management-as-agent-management thesis; also connects to Marily Nika's AI product sense (evaluation as core skill)

## Raw Content

*Validated via WebFetch against live source 2026-02-16. Content captured from inbox clip (source: clip, 2026-02-14). Full article publicly available at source URL.*

### Article Structure

**Opening — UPenn MBA startup experiment**: Students in an executive MBA class were challenged to create a startup from scratch in 4 days using Claude Code, Google Antigravity, ChatGPT, Claude, and Gemini. Author has 15 years of teaching entrepreneurship — estimates these students got an order of magnitude further than pre-AI students working a full semester. Prototypes had core features working, ideas were more diverse, analyses more insightful. Key enabler: lowered cost of pivoting meant students could explore multiple directions freely.

**The delegation decision framework**: Three factors from the Jagged Frontier of AI ability:
1. You don't reliably know what AI will be good or bad at on complex tasks
2. AI is fast — produces in minutes what takes humans hours
3. AI is cheap relative to professional wages; doesn't mind if you discard most outputs

Three variables for the delegation decision:
- **Human Baseline Time** — how long the task takes you
- **Probability of Success** — likelihood AI produces acceptable output
- **AI Process Time** — time to request, wait, and evaluate

Tradeoff: you're exchanging "doing the whole task" against "paying the overhead cost" of AI evaluation, possibly multiple times. A 1-hour task with 30-min evaluation only works if success probability is very high. A 10-hour task justifies several hours of working with AI.

**GDPval evidence**: OpenAI study pitting human experts against AI on diverse professional tasks. Expert tasks averaged 7 hours (Human Baseline Time). AI took minutes but evaluation took 1 hour (AI Process Time). With GPT-5.2, Probability of Success reached ~72% (tied or beat experts). Math: on a 7-hour task with 72% success and 1 hour evaluation, you save ~3 hours on average. Failed tasks cost more (wasted prompting + review time), but successes are much faster.

**Three levers to improve the equation**:
1. Better instructions — clear goals increase Probability of Success
2. Better evaluation and feedback — fewer iteration attempts needed
3. Cheaper evaluation — less time to assess quality

All three are improved by subject matter expertise — experts know what instructions to give, spot errors faster, correct more efficiently.

**Delegation documentation as AI prompts**: PRDs, shot lists, design intent documents, Five Paragraph Orders (Marines), engagement scopes — all solve the same problem (getting intent into action) and all work as AI prompts. They share common elements: what are we trying to accomplish and why? Where are the limits? What does "done" look like? What outputs do I need? What interim checkpoints? What quality checks before completion?

**Management as the meta-skill**: Software developers at AI labs note their jobs shifting from mostly programming to mostly managing AI agents. Coding matured first (clearly verifiable outputs), but other fields will follow. Management 101 skills transfer: explain what you need, give feedback, evaluate work. But the scarcity has inverted — talent is now abundant, knowing what to ask for is scarce.

**Conclusion**: The MBA students succeeded not because they were AI natives but because they already knew how to manage — scope problems, define deliverables, recognize quality. Management training was accidentally preparing them for exactly this moment.
