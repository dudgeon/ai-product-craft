---
created: 2026-02-19
updated: 2026-02-19
template: templates/knowledge-entry.md
template_version: 5
tags: [knowledge, ai-pm]
status: draft
entry_type: technique
origin: sourced
featured: false
domain: ai-adoption
project: ai-pm
---

# Intentional Understaffing for AI-First Teams

## Summary

When Boris Cherny wants a team to truly adopt AI-native ways of working, he puts one engineer on a project instead of three. Not as a budget decision — as an intentional forcing function. With one person on the project, they *have* to let AI do more. The constraint drives creative, high-leverage use of AI tooling in a way that sufficient staffing never does. A fully-staffed team can always route around the AI when it's inconvenient; an understaffed team cannot.

The distinction Cherny makes is important: constraint drives creative *use* of AI, not just faster typing. A team using AI as a turbocharger for existing habits will miss the architectural shifts that genuinely change what's possible. A team that *has* to figure out AI-native approaches will discover them.

## How to Apply

- **When starting a new AI-native project**: Deliberately start with one engineer (or a smaller team than the project seems to warrant). Let AI carry the work you haven't staffed for. Evaluate what's possible before defaulting to headcount.
- **For driving adoption on existing teams**: Identify one project or initiative and run it deliberately under-resourced. Use the constraint to surface what AI workflows are actually capable of. Share learnings across the team.
- **Set explicit expectations**: Make clear to the engineer that this isn't a performance test — it's an AI capability test. The question is "what can AI do on this project?" not "how fast can you work?"
- **Scale only after the proof of concept**: If the AI-native approach works at small scale, staff up. If it doesn't work, the cost of finding out was one engineer, not a team.

Note: this is a leadership technique, not an individual practice. It requires a manager who can protect the engineer from scope creep and can frame the constraint correctly.

## Sources

### From: [2026-02-19 Head of Claude Code: What Happens After Coding Is Solved](../sources/2026-02-19-head-of-claude-code-boris-cherny.md)
**Key quote**: "When Boris puts one engineer on a project, they're forced to let AI do more of the work. Constraint drives creative use of AI tooling, not just faster typing."
**Attribution**: Boris Cherny
**What this source adds**: Cherny practices this at Anthropic, the company that builds Claude Code. The technique comes from someone who has direct visibility into what AI can do and is deliberately using constraint to force discovery.
**Links**: [Original](https://www.lennysnewsletter.com/p/head-of-claude-code-what-happens) | [Archive](../sources/2026-02-19-head-of-claude-code-boris-cherny.md)

## Related

- [Delay Token Cost Optimization](delay-token-cost-optimization.md) — Understaffing only works if you also give the team unlimited tokens; pairing both creates the right AI-first forcing function
- [Build for Future Model Capability](build-for-future-model-capability.md) — Understaffing is the forcing function for adoption; future-model design frames what the team is building toward
- [Raise the Floor vs Raise the Ceiling](raise-the-floor-vs-raise-the-ceiling.md) — Understaffing is a ceiling-raising technique; it surfaces what's possible at the frontier, not what scales to everyone
